{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes\n",
    "# This is code for a plotly dash app for heroku\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so more head displays\n",
    "#override display option\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val = pd.read_csv ('https://raw.githubusercontent.com/lineality/lending_project_1/master/val_loanclub_wrangled_sm4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = pd.read_csv ('https://raw.githubusercontent.com/lineality/lending_project_1/master/train_loanclub_wrangled_sm4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linea\\Anaconda3\\envs\\unit2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (19,47,55,112,123,124,125,128,129,130,133,139,140,141) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#file from computer drive\n",
    "df_all = pd.read_csv(r\"C:\\Users\\linea\\Downloads\\data\\lending club\\lending_club_loans_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if file in local environment\n",
    "#df_all = pd.read_csv('lending_club_loans_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask = {'Current': 1, 'Charged Off': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask = {'Current': 1, 'Charged Off': 0}\n",
    "#3df['loan_status'] = df['loan_status'].replace({'Current': mask, 'Charged Off': mask})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>url</th>\n",
       "      <th>desc</th>\n",
       "      <th>purpose</th>\n",
       "      <th>title</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>initial_list_status</th>\n",
       "      <th>out_prncp</th>\n",
       "      <th>out_prncp_inv</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>total_pymnt_inv</th>\n",
       "      <th>total_rec_prncp</th>\n",
       "      <th>total_rec_int</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>recoveries</th>\n",
       "      <th>collection_recovery_fee</th>\n",
       "      <th>last_pymnt_d</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>next_pymnt_d</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>mths_since_last_major_derog</th>\n",
       "      <th>policy_code</th>\n",
       "      <th>application_type</th>\n",
       "      <th>annual_inc_joint</th>\n",
       "      <th>dti_joint</th>\n",
       "      <th>verification_status_joint</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>tot_coll_amt</th>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <th>open_acc_6m</th>\n",
       "      <th>open_act_il</th>\n",
       "      <th>open_il_12m</th>\n",
       "      <th>open_il_24m</th>\n",
       "      <th>mths_since_rcnt_il</th>\n",
       "      <th>total_bal_il</th>\n",
       "      <th>il_util</th>\n",
       "      <th>open_rv_12m</th>\n",
       "      <th>open_rv_24m</th>\n",
       "      <th>max_bal_bc</th>\n",
       "      <th>all_util</th>\n",
       "      <th>total_rev_hi_lim</th>\n",
       "      <th>inq_fi</th>\n",
       "      <th>total_cu_tl</th>\n",
       "      <th>inq_last_12m</th>\n",
       "      <th>acc_open_past_24mths</th>\n",
       "      <th>avg_cur_bal</th>\n",
       "      <th>bc_open_to_buy</th>\n",
       "      <th>bc_util</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>mo_sin_old_il_acct</th>\n",
       "      <th>mo_sin_old_rev_tl_op</th>\n",
       "      <th>mo_sin_rcnt_rev_tl_op</th>\n",
       "      <th>mo_sin_rcnt_tl</th>\n",
       "      <th>mort_acc</th>\n",
       "      <th>mths_since_recent_bc</th>\n",
       "      <th>mths_since_recent_bc_dlq</th>\n",
       "      <th>mths_since_recent_inq</th>\n",
       "      <th>mths_since_recent_revol_delinq</th>\n",
       "      <th>num_accts_ever_120_pd</th>\n",
       "      <th>num_actv_bc_tl</th>\n",
       "      <th>num_actv_rev_tl</th>\n",
       "      <th>num_bc_sats</th>\n",
       "      <th>num_bc_tl</th>\n",
       "      <th>num_il_tl</th>\n",
       "      <th>num_op_rev_tl</th>\n",
       "      <th>num_rev_accts</th>\n",
       "      <th>num_rev_tl_bal_gt_0</th>\n",
       "      <th>num_sats</th>\n",
       "      <th>num_tl_120dpd_2m</th>\n",
       "      <th>num_tl_30dpd</th>\n",
       "      <th>num_tl_90g_dpd_24m</th>\n",
       "      <th>num_tl_op_past_12m</th>\n",
       "      <th>pct_tl_nvr_dlq</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <th>total_bal_ex_mort</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>total_il_high_credit_limit</th>\n",
       "      <th>revol_bal_joint</th>\n",
       "      <th>sec_app_earliest_cr_line</th>\n",
       "      <th>sec_app_inq_last_6mths</th>\n",
       "      <th>sec_app_mort_acc</th>\n",
       "      <th>sec_app_open_acc</th>\n",
       "      <th>sec_app_revol_util</th>\n",
       "      <th>sec_app_open_act_il</th>\n",
       "      <th>sec_app_num_rev_accts</th>\n",
       "      <th>sec_app_chargeoff_within_12_mths</th>\n",
       "      <th>sec_app_collections_12_mths_ex_med</th>\n",
       "      <th>sec_app_mths_since_last_major_derog</th>\n",
       "      <th>hardship_flag</th>\n",
       "      <th>hardship_type</th>\n",
       "      <th>hardship_reason</th>\n",
       "      <th>hardship_status</th>\n",
       "      <th>deferral_term</th>\n",
       "      <th>hardship_amount</th>\n",
       "      <th>hardship_start_date</th>\n",
       "      <th>hardship_end_date</th>\n",
       "      <th>payment_plan_start_date</th>\n",
       "      <th>hardship_length</th>\n",
       "      <th>hardship_dpd</th>\n",
       "      <th>hardship_loan_status</th>\n",
       "      <th>orig_projected_additional_accrued_interest</th>\n",
       "      <th>hardship_payoff_balance_amount</th>\n",
       "      <th>hardship_last_payment_amount</th>\n",
       "      <th>disbursement_method</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "      <th>debt_settlement_flag_date</th>\n",
       "      <th>settlement_status</th>\n",
       "      <th>settlement_date</th>\n",
       "      <th>settlement_amount</th>\n",
       "      <th>settlement_percentage</th>\n",
       "      <th>settlement_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.56</td>\n",
       "      <td>84.92</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>Chef</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Dec-2018</td>\n",
       "      <td>Current</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>Debt consolidation</td>\n",
       "      <td>109xx</td>\n",
       "      <td>NY</td>\n",
       "      <td>18.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Apr-2001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4341</td>\n",
       "      <td>10.3</td>\n",
       "      <td>34.0</td>\n",
       "      <td>w</td>\n",
       "      <td>2386.02</td>\n",
       "      <td>2386.02</td>\n",
       "      <td>167.02</td>\n",
       "      <td>167.02</td>\n",
       "      <td>113.98</td>\n",
       "      <td>53.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb-2019</td>\n",
       "      <td>84.92</td>\n",
       "      <td>Mar-2019</td>\n",
       "      <td>Feb-2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Individual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16901.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12560.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2137.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>34360.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60124.0</td>\n",
       "      <td>16901.0</td>\n",
       "      <td>36500.0</td>\n",
       "      <td>18124.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>18.94</td>\n",
       "      <td>777.23</td>\n",
       "      <td>D</td>\n",
       "      <td>D2</td>\n",
       "      <td>Postmaster</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Dec-2018</td>\n",
       "      <td>Current</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>Debt consolidation</td>\n",
       "      <td>713xx</td>\n",
       "      <td>LA</td>\n",
       "      <td>26.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jun-1987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12315</td>\n",
       "      <td>24.2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>w</td>\n",
       "      <td>29387.75</td>\n",
       "      <td>29387.75</td>\n",
       "      <td>1507.11</td>\n",
       "      <td>1507.11</td>\n",
       "      <td>612.25</td>\n",
       "      <td>894.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb-2019</td>\n",
       "      <td>777.23</td>\n",
       "      <td>Mar-2019</td>\n",
       "      <td>Feb-2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Individual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>321915.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>87153.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>50800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>24763.0</td>\n",
       "      <td>13761.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372872.0</td>\n",
       "      <td>99468.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>94072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>17.97</td>\n",
       "      <td>180.69</td>\n",
       "      <td>D</td>\n",
       "      <td>D1</td>\n",
       "      <td>Administrative</td>\n",
       "      <td>6 years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>59280.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Dec-2018</td>\n",
       "      <td>Current</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>Debt consolidation</td>\n",
       "      <td>490xx</td>\n",
       "      <td>MI</td>\n",
       "      <td>10.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Apr-2011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4599</td>\n",
       "      <td>19.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>w</td>\n",
       "      <td>4787.21</td>\n",
       "      <td>4787.21</td>\n",
       "      <td>353.89</td>\n",
       "      <td>353.89</td>\n",
       "      <td>212.79</td>\n",
       "      <td>141.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb-2019</td>\n",
       "      <td>180.69</td>\n",
       "      <td>Mar-2019</td>\n",
       "      <td>Feb-2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Individual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110299.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7150.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>24100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18383.0</td>\n",
       "      <td>13800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136927.0</td>\n",
       "      <td>11749.0</td>\n",
       "      <td>13800.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  int_rate  installment grade sub_grade       emp_title emp_length home_ownership  annual_inc verification_status   issue_d loan_status pymnt_plan  url desc             purpose               title zip_code addr_state    dti  delinq_2yrs earliest_cr_line  inq_last_6mths  mths_since_last_delinq  mths_since_last_record  open_acc  pub_rec  revol_bal  revol_util  total_acc initial_list_status  out_prncp  out_prncp_inv  total_pymnt  total_pymnt_inv  total_rec_prncp  total_rec_int  total_rec_late_fee  recoveries  collection_recovery_fee last_pymnt_d  last_pymnt_amnt next_pymnt_d last_credit_pull_d  collections_12_mths_ex_med  mths_since_last_major_derog  policy_code application_type  annual_inc_joint  dti_joint verification_status_joint  acc_now_delinq  tot_coll_amt  tot_cur_bal  open_acc_6m  open_act_il  open_il_12m  open_il_24m  mths_since_rcnt_il  total_bal_il  il_util  open_rv_12m  open_rv_24m  max_bal_bc  all_util  \\\n",
       "0 NaN        NaN       2500         2500           2500.0   36 months     13.56        84.92     C        C1            Chef  10+ years           RENT     55000.0        Not Verified  Dec-2018     Current          n  NaN  NaN  debt_consolidation  Debt consolidation    109xx         NY  18.24          0.0         Apr-2001             1.0                     NaN                    45.0       9.0      1.0       4341        10.3       34.0                   w    2386.02        2386.02       167.02           167.02           113.98          53.04                 0.0         0.0                      0.0     Feb-2019            84.92     Mar-2019           Feb-2019                         0.0                          NaN            1       Individual               NaN        NaN                       NaN             0.0           0.0      16901.0          2.0          2.0          1.0          2.0                 2.0       12560.0     69.0          2.0          7.0      2137.0      28.0   \n",
       "1 NaN        NaN      30000        30000          30000.0   60 months     18.94       777.23     D        D2     Postmaster   10+ years       MORTGAGE     90000.0     Source Verified  Dec-2018     Current          n  NaN  NaN  debt_consolidation  Debt consolidation    713xx         LA  26.52          0.0         Jun-1987             0.0                    71.0                    75.0      13.0      1.0      12315        24.2       44.0                   w   29387.75       29387.75      1507.11          1507.11           612.25         894.86                 0.0         0.0                      0.0     Feb-2019           777.23     Mar-2019           Feb-2019                         0.0                          NaN            1       Individual               NaN        NaN                       NaN             0.0        1208.0     321915.0          4.0          4.0          2.0          3.0                 3.0       87153.0     88.0          4.0          5.0       998.0      57.0   \n",
       "2 NaN        NaN       5000         5000           5000.0   36 months     17.97       180.69     D        D1  Administrative    6 years       MORTGAGE     59280.0     Source Verified  Dec-2018     Current          n  NaN  NaN  debt_consolidation  Debt consolidation    490xx         MI  10.51          0.0         Apr-2011             0.0                     NaN                     NaN       8.0      0.0       4599        19.1       13.0                   w    4787.21        4787.21       353.89           353.89           212.79         141.10                 0.0         0.0                      0.0     Feb-2019           180.69     Mar-2019           Feb-2019                         0.0                          NaN            1       Individual               NaN        NaN                       NaN             0.0           0.0     110299.0          0.0          1.0          0.0          2.0                14.0        7150.0     72.0          0.0          2.0         0.0      35.0   \n",
       "\n",
       "   total_rev_hi_lim  inq_fi  total_cu_tl  inq_last_12m  acc_open_past_24mths  avg_cur_bal  bc_open_to_buy  bc_util  chargeoff_within_12_mths  delinq_amnt  mo_sin_old_il_acct  mo_sin_old_rev_tl_op  mo_sin_rcnt_rev_tl_op  mo_sin_rcnt_tl  mort_acc  mths_since_recent_bc  mths_since_recent_bc_dlq  mths_since_recent_inq  mths_since_recent_revol_delinq  num_accts_ever_120_pd  num_actv_bc_tl  num_actv_rev_tl  num_bc_sats  num_bc_tl  num_il_tl  num_op_rev_tl  num_rev_accts  num_rev_tl_bal_gt_0  num_sats  num_tl_120dpd_2m  num_tl_30dpd  num_tl_90g_dpd_24m  num_tl_op_past_12m  pct_tl_nvr_dlq  percent_bc_gt_75  pub_rec_bankruptcies  tax_liens  tot_hi_cred_lim  total_bal_ex_mort  total_bc_limit  total_il_high_credit_limit  revol_bal_joint sec_app_earliest_cr_line  sec_app_inq_last_6mths  sec_app_mort_acc  sec_app_open_acc  sec_app_revol_util  sec_app_open_act_il  sec_app_num_rev_accts  sec_app_chargeoff_within_12_mths  sec_app_collections_12_mths_ex_med  sec_app_mths_since_last_major_derog  \\\n",
       "0           42000.0     1.0         11.0           2.0                   9.0       1878.0         34360.0      5.9                       0.0          0.0               140.0                 212.0                    1.0             1.0       0.0                   1.0                       NaN                    2.0                             NaN                    0.0             2.0              5.0          3.0        3.0       16.0            7.0           18.0                  5.0       9.0               0.0           0.0                 0.0                 3.0           100.0               0.0                   1.0        0.0          60124.0            16901.0         36500.0                     18124.0              NaN                      NaN                     NaN               NaN               NaN                 NaN                  NaN                    NaN                               NaN                                 NaN                                  NaN   \n",
       "1           50800.0     2.0         15.0           2.0                  10.0      24763.0         13761.0      8.3                       0.0          0.0               163.0                 378.0                    4.0             3.0       3.0                   4.0                       NaN                    4.0                             NaN                    0.0             2.0              4.0          4.0        9.0       27.0            8.0           14.0                  4.0      13.0               0.0           0.0                 0.0                 6.0            95.0               0.0                   1.0        0.0         372872.0            99468.0         15000.0                     94072.0              NaN                      NaN                     NaN               NaN               NaN                 NaN                  NaN                    NaN                               NaN                                 NaN                                  NaN   \n",
       "2           24100.0     1.0          5.0           0.0                   4.0      18383.0         13800.0      0.0                       0.0          0.0                87.0                  92.0                   15.0            14.0       2.0                  77.0                       NaN                   14.0                             NaN                    0.0             0.0              3.0          3.0        3.0        4.0            6.0            7.0                  3.0       8.0               0.0           0.0                 0.0                 0.0           100.0               0.0                   0.0        0.0         136927.0            11749.0         13800.0                     10000.0              NaN                      NaN                     NaN               NaN               NaN                 NaN                  NaN                    NaN                               NaN                                 NaN                                  NaN   \n",
       "\n",
       "  hardship_flag hardship_type hardship_reason hardship_status  deferral_term  hardship_amount hardship_start_date hardship_end_date payment_plan_start_date  hardship_length  hardship_dpd hardship_loan_status  orig_projected_additional_accrued_interest  hardship_payoff_balance_amount  hardship_last_payment_amount disbursement_method debt_settlement_flag debt_settlement_flag_date settlement_status settlement_date  settlement_amount  settlement_percentage  settlement_term  \n",
       "0             N           NaN             NaN             NaN            NaN              NaN                 NaN               NaN                     NaN              NaN           NaN                  NaN                                         NaN                             NaN                           NaN                Cash                    N                       NaN               NaN             NaN                NaN                    NaN              NaN  \n",
       "1             N           NaN             NaN             NaN            NaN              NaN                 NaN               NaN                     NaN              NaN           NaN                  NaN                                         NaN                             NaN                           NaN                Cash                    N                       NaN               NaN             NaN                NaN                    NaN              NaN  \n",
       "2             N           NaN             NaN             NaN            NaN              NaN                 NaN               NaN                     NaN              NaN           NaN                  NaN                                         NaN                             NaN                           NaN                Cash                    N                       NaN               NaN             NaN                NaN                    NaN              NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main contributing features:\n",
    "# +  dti term total acc\n",
    "# - sub_grade, term, dti, num_actv, issue_d_year, home_ownership\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# including only clean, no_time_leak, columns\n",
    "\n",
    "# Only use these features which had nonzero permutation importances in earlier models    \n",
    "df = df_all.filter(['disbursement_method',\n",
    "        'debt_settlement_flag',\n",
    "        'hardship_flag',\n",
    "        #is delinq_amnt leakage?\n",
    "        #'delinq_amnt',\n",
    "        #is acc_now_delinq leakage?\n",
    "        #'acc_now_delinq',\n",
    "        'policy_code',\n",
    "        'application_type',\n",
    "        #'last_pymnt_amnt',#maybe time leak\n",
    "        'total_acc', #keep this\n",
    "        'initial_list_statu',\n",
    "                    \n",
    "        #'out_prncp',\n",
    "        #'out_prncp_inv',#redundant?\n",
    "        #'total_pymnt',\n",
    "                    \n",
    "        #'total_pymnt_inv',#redundant?\n",
    "#total_rec: here there are issues with leakage and inclusion...e.g. people who paid early but paid in full?\n",
    "        #'total_rec_prncp',\n",
    "        #'total_rec_int',\n",
    "        #'total_rec_late_fee',\n",
    "        #'recoveries',#this may involve loan deliquency time leak\n",
    "        #'collection_recovery_fee',#this may involve loan deliquency time leak\n",
    "                    \n",
    "        'open_acc', #number of open trades since openind account (time leak?)\n",
    "        'pub_rec',\n",
    "        'revol_bal',\n",
    "                    \n",
    "        #is delinq_2yrs leakage?\n",
    "        #'delinq_2yrs',\n",
    "        #'inq_last_6mths',\n",
    "                    \n",
    "        #'addr_state',\n",
    "        'purpose',\n",
    "        'earliest_cr_line',\n",
    "        'home_ownership', #keep this\n",
    "        'annual_inc',\n",
    "        'verification_status',\n",
    "        'issue_d', #keep this\n",
    "        'loan_status',#target\n",
    "        'pymnt_pla',\n",
    "        'loan_amnt',\n",
    "        'funded_amnt',\n",
    "                    \n",
    "        #'funded_amnt_inv',#redundant?\n",
    "                    \n",
    "        'term', # keep this\n",
    "        'int_rate',\n",
    "        'installment',\n",
    "        'grade',\n",
    "        'sub_grade']) # keep this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['issue_d'] = pd.to_datetime(df['issue_d'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2260668, 23)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disbursement_method</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "      <th>hardship_flag</th>\n",
       "      <th>policy_code</th>\n",
       "      <th>application_type</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>purpose</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>Individual</td>\n",
       "      <td>34.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4341</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>Apr-2001</td>\n",
       "      <td>RENT</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Dec-2018</td>\n",
       "      <td>Current</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.56</td>\n",
       "      <td>84.92</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>Individual</td>\n",
       "      <td>44.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12315</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>Jun-1987</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Dec-2018</td>\n",
       "      <td>Current</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>60 months</td>\n",
       "      <td>18.94</td>\n",
       "      <td>777.23</td>\n",
       "      <td>D</td>\n",
       "      <td>D2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  disbursement_method debt_settlement_flag hardship_flag  policy_code application_type  total_acc  open_acc  pub_rec  revol_bal             purpose earliest_cr_line home_ownership  annual_inc verification_status   issue_d loan_status  loan_amnt  funded_amnt        term  int_rate  installment grade sub_grade\n",
       "0                Cash                    N             N            1       Individual       34.0       9.0      1.0       4341  debt_consolidation         Apr-2001           RENT     55000.0        Not Verified  Dec-2018     Current       2500         2500   36 months     13.56        84.92     C        C1\n",
       "1                Cash                    N             N            1       Individual       44.0      13.0      1.0      12315  debt_consolidation         Jun-1987       MORTGAGE     90000.0     Source Verified  Dec-2018     Current      30000        30000   60 months     18.94       777.23     D        D2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf = df[df.loan_status != 'Default']\\ndf = df[df.loan_status != 'Late (31-120 days)']\\ndf = df[df.loan_status != 'Late (16-30 days)']\\ndf = df[df.loan_status != 'In Grace Period'] \\ndf = df[df.loan_status != 'Current']\\ndf = df[df.loan_status != 'Does not meet the credit policy. Status:Fully Paid']\\ndf = df[df.loan_status != 'Does not meet the credit policy. Status:Charged Off']\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this was moved to the Mangle...Wrangle Function\n",
    "#the remaining options should be:\n",
    "#Fully Paid                                             1041952\n",
    "#Charged Off                                             261655\n",
    "\n",
    "#df = df[df.loan_status != 'Current']\n",
    "\"\"\"\n",
    "df = df[df.loan_status != 'Default']\n",
    "df = df[df.loan_status != 'Late (31-120 days)']\n",
    "df = df[df.loan_status != 'Late (16-30 days)']\n",
    "df = df[df.loan_status != 'In Grace Period'] \n",
    "df = df[df.loan_status != 'Current']\n",
    "df = df[df.loan_status != 'Does not meet the credit policy. Status:Fully Paid']\n",
    "df = df[df.loan_status != 'Does not meet the credit policy. Status:Charged Off']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This displays the original catagories including current and past loans,\n",
    "# of which only past loans should be included: \n",
    "#FUlly Paid vs. charged off\n",
    "#df['loan_status'].value_counts().sort_values(ascending=False)#[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['issue_d'].value_counts().sort_values(ascending=False)#[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['loan_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CurrentFully PaidLate (31-120 days)In Grace PeriodCharged OffLate (16-30 days)DefaultDoes not meet the credit policy. Status:Fully PaidDoes not meet the credit policy. Status:Charged Off'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['loan_status'].unique().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fully Paid                                             1041952\n",
       "Current                                                 919695\n",
       "Charged Off                                             261655\n",
       "Late (31-120 days)                                       21897\n",
       "In Grace Period                                           8952\n",
       "Late (16-30 days)                                         3737\n",
       "Does not meet the credit policy. Status:Fully Paid        1988\n",
       "Does not meet the credit policy. Status:Charged Off        761\n",
       "Default                                                     31\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['loan_status'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fully Paid                                             1041952\n",
       "Current                                                 919695\n",
       "Charged Off                                             261655\n",
       "Late (31-120 days)                                       21897\n",
       "In Grace Period                                           8952\n",
       "Late (16-30 days)                                         3737\n",
       "Does not meet the credit policy. Status:Fully Paid        1988\n",
       "Does not meet the credit policy. Status:Charged Off        761\n",
       "Default                                                     31\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['loan_status'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['issue_d'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe(exclude='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: 2 splits, both based on time. \n",
    "\n",
    "# remove all the current loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, Validate, Test Splits\n",
    "# for an uploadable the dataset the size must be reduced.\n",
    "\n",
    "target = 'loan_status'\n",
    "\n",
    "# time based split\n",
    "\n",
    "\n",
    "\n",
    "df[\"issue_d\"] = pd.to_datetime(df[\"issue_d\"], infer_datetime_format=True)\n",
    "test = df[df['issue_d'] >= '2018-12-01 00:00:00']\n",
    "train_and_val = df[df['issue_d'] < '2018-12-01 00:00:00']\n",
    "\n",
    "\n",
    "val = train_and_val[train_and_val['issue_d'] >= '2018-08-01 00:00:00']\n",
    "train = train_and_val[train_and_val['issue_d'] < '2018-08-01 00:00:00']\n",
    "\n",
    "#original\n",
    "# df[\"issue_d\"] = pd.to_datetime(df[\"issue_d\"], infer_datetime_format=True)\n",
    "# test = df[df['issue_d'] >= '2018-07-01 00:00:00']\n",
    "# train_and_val = df[df['issue_d'] < '2018-07-01 00:00:00']\n",
    "\n",
    "\n",
    "# val = train_and_val[train_and_val['issue_d'] < '2016-07-01 00:00:00']\n",
    "# train = train_and_val[train_and_val['issue_d'] >= '2016-07-01 00:00:00']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2047151, 23), (173383, 23), (40134, 23))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disbursement_method</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "      <th>hardship_flag</th>\n",
       "      <th>policy_code</th>\n",
       "      <th>application_type</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>purpose</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>Individual</td>\n",
       "      <td>34.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4341</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>Apr-2001</td>\n",
       "      <td>RENT</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>Current</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.56</td>\n",
       "      <td>84.92</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>Individual</td>\n",
       "      <td>44.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12315</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>Jun-1987</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>Current</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>60 months</td>\n",
       "      <td>18.94</td>\n",
       "      <td>777.23</td>\n",
       "      <td>D</td>\n",
       "      <td>D2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  disbursement_method debt_settlement_flag hardship_flag  policy_code application_type  total_acc  open_acc  pub_rec  revol_bal             purpose earliest_cr_line home_ownership  annual_inc verification_status    issue_d loan_status  loan_amnt  funded_amnt        term  int_rate  installment grade sub_grade\n",
       "0                Cash                    N             N            1       Individual       34.0       9.0      1.0       4341  debt_consolidation         Apr-2001           RENT     55000.0        Not Verified 2018-12-01     Current       2500         2500   36 months     13.56        84.92     C        C1\n",
       "1                Cash                    N             N            1       Individual       44.0      13.0      1.0      12315  debt_consolidation         Jun-1987       MORTGAGE     90000.0     Source Verified 2018-12-01     Current      30000        30000   60 months     18.94       777.23     D        D2"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "    df['loan_status'].replace('Fully Paid', 1, inplace=True)\n",
    "    df['loan_status'].replace('Charged Off', 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrangle Function + Make Family of Variables\n",
    "\n",
    "\n",
    "\n",
    "def wrangle(X):\n",
    "    #Wrangles train, validate, and test sets in the same way\n",
    "    X = X.copy()\n",
    "\n",
    "    # Convert date_recorded to datetime\n",
    "    #X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
    "    #X['issue_d'] = pd.to_datetime(X['issue_d'], infer_datetime_format=True)\n",
    "    \n",
    "    # Extract components from date_recorded, then drop the original column\n",
    "    X['year'] = X['issue_d'].dt.year\n",
    "    X['month'] = X['issue_d'].dt.month\n",
    "    X['day'] = X['issue_d'].dt.day\n",
    "    X = X.drop(columns='issue_d')\n",
    "    \n",
    "    # Engineer feature: how many years from construction_year to date_recorded\n",
    "    #X['years'] = X['year_recorded'] - X['construction_year']    \n",
    "    \n",
    "    # Drop recorded_by (never varies) and id (always varies, random)\n",
    "    #unusable_variance = ['recorded_by', 'id']\n",
    "    #X = X.drop(columns=unusable_variance)\n",
    "    \n",
    "    \n",
    "    # Removing current rows (to avoid time-leakage/time-travel)\n",
    "    #the remaining options should be:\n",
    "    #Fully Paid                                             1041952\n",
    "    #Charged Off                                             261655\n",
    "    #df = df[df.loan_status != 'Current']\n",
    "    X = X[X.loan_status != 'Default']\n",
    "    X = X[X.loan_status != 'Late (31-120 days)']\n",
    "    X = X[X.loan_status != 'Late (16-30 days)']\n",
    "    X = X[X.loan_status != 'In Grace Period'] \n",
    "    X = X[X.loan_status != 'Current']\n",
    "    X = X[X.loan_status != 'Does not meet the credit policy. Status:Fully Paid']\n",
    "    X = X[X.loan_status != 'Does not meet the credit policy. Status:Charged Off']\n",
    "    \n",
    "    #X = X.dropna()\n",
    "    mask = {'Current': 1, 'Charged Off': 0}\n",
    "    X['loan_status'] = X['loan_status'].replace({'Current': mask, 'Charged Off': mask})\n",
    "\n",
    "    # Drop duplicate columns\n",
    "    #duplicate_columns = ['quantity_group']\n",
    "    #X = X.drop(columns=duplicate_columns)\n",
    "    '''\n",
    "    #dropping rows\n",
    "    #not looking at current-incomplete loan data\n",
    "    #removing not-current rows\n",
    "    X = X[X.loan_status != 'Default']\n",
    "    X = X[X.loan_status != 'Late (31-120 days)']\n",
    "    X = X[X.loan_status != 'Late (16-30 days)']\n",
    "    X = X[X.loan_status != 'In Grace Period'] \n",
    "    X = X[X.loan_status != 'Current']\n",
    "    X = X[X.loan_status != 'Does not meet the credit policy. Status:Fully Paid']\n",
    "    X = X[X.loan_status != 'Does not meet the credit policy. Status:Charged Off']\n",
    "    \n",
    "    \n",
    "    # Drop empty NaN columns\n",
    "    empty_columns = ['quantity_group',\n",
    "                    'revol_bal_joint',\n",
    "                    'sec_app_earliest_cr_line',\n",
    "                    'sec_app_inq_last_6mths',\n",
    "                    'sec_app_mort_acc',\n",
    "                    'sec_app_open_acc',\n",
    "                    'sec_app_revol_util',\n",
    "                    'sec_app_open_act_il',\n",
    "                    'sec_app_num_rev_accts',\n",
    "                    'sec_app_chargeoff_within_12_mths',\n",
    "                    'sec_app_collections_12_mths_ex_med',\n",
    "                    'sec_app_mths_since_last_major_derog',\n",
    "                    'hardship_type',\n",
    "                    'hardship_reason',\n",
    "                    'hardship_status',\n",
    "                    'deferral_term',\n",
    "                    'hardship_amount',\n",
    "                    'hardship_start_date',\n",
    "                    'hardship_end_date',\n",
    "                    'payment_plan_start_date',\n",
    "                    'hardship_length',\n",
    "                    'hardship_dpd',\n",
    "                    'hardship_loan_status',\n",
    "                    'orig_projected_additional_accrued_interest',\n",
    "                    'hardship_payoff_balance_amount',\n",
    "                    'hardship_last_payment_amount',\n",
    "                    'debt_settlement_flag_date',\n",
    "                    'settlement_status',\n",
    "                    'settlement_date',\n",
    "                    'settlement_amount',\n",
    "                    'settlement_percentage',\n",
    "                    'settlement_term',\n",
    "                    'id',\n",
    "                    'member_id',\n",
    "                    'url',\n",
    "                    'desc',\n",
    "                    'mths_since_last_delinq',\n",
    "                    'mths_since_last_record',\n",
    "                    'next_pymnt_d',\n",
    "                    'annual_inc_joint',\n",
    "                    'dti_joint',\n",
    "                    'verification_status_joint'\n",
    "                     ]\n",
    "    \n",
    "    X = X.drop(columns=empty_columns)\n",
    "    '''\n",
    "    # About 3% of the time, latitude has small values near zero,\n",
    "    # outside Tanzania, so we'll treat these like null values\n",
    "    #X['latitude'] = X['latitude'].replace(-2e-08, np.nan)\n",
    "    \n",
    "    # When columns have zeros and shouldn't, they are like null values\n",
    "    #cols_with_zeros = ['construction_year', 'longitude', 'latitude', 'gps_height', 'population']\n",
    "    #for col in cols_with_zeros:\n",
    "    #    X[col] = X[col].replace(0, np.nan)\n",
    "        \n",
    "    return X\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2(or 4) splits\n",
    "# df -> train_and_validate and test\n",
    "# train_val -> train and val\n",
    "# Split train into train & val. Make val the same size as test.\n",
    "\n",
    "\n",
    "#train, val = train_test_split(train, test_size=len(test),  \n",
    "#                              stratify=train[target], random_state=42)\n",
    "\n",
    "# Wrangle train, validate, and test sets in the same way\n",
    "train = wrangle(train)\n",
    "val = wrangle(val)\n",
    "test = wrangle(test)\n",
    "#df_small = wrangle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking to see if current options (rows leaking from future) were removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1034165\n",
       "0     261367\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['loan_status'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6964\n",
       "0     286\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val['loan_status'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    823\n",
       "0      2\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['loan_status'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports df (current working directory)\n",
    "#train.to_csv('train_loanclub_wrangled_sm4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports df (current working directory)\n",
    "#val.to_csv('val_loanclub_wrangled_sm4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports df (current working directory)\n",
    "#test.to_csv('test_loanclub_wrangled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange data into X features matrix and y target vector\n",
    "X_train = train.drop(columns=target)\n",
    "y_train = train[target]\n",
    "\n",
    "X_val = val.drop(columns=target)\n",
    "y_val = val[target]\n",
    "\n",
    "X_test = test.drop(columns=target)\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1295532, 24), (7250, 24), (825, 24), (1295532,), (7250,), (825,))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212552    1\n",
       "212610    1\n",
       "212611    1\n",
       "Name: loan_status, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1295532\n",
       "unique          2\n",
       "top             1\n",
       "freq      1034165\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['loan_status'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7472676023651932"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline of majority class\n",
    "1-(261367/1034165)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.295532e+06\n",
       "mean     1.325242e+01\n",
       "std      4.753612e+00\n",
       "min      5.310000e+00\n",
       "25%      9.750000e+00\n",
       "50%      1.274000e+01\n",
       "75%      1.599000e+01\n",
       "max      3.099000e+01\n",
       "Name: int_rate, dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['int_rate'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.295532e+06\n",
       "mean     1.441783e+04\n",
       "std      8.690174e+03\n",
       "min      5.000000e+02\n",
       "25%      8.000000e+03\n",
       "50%      1.200000e+04\n",
       "75%      2.000000e+04\n",
       "max      4.000000e+04\n",
       "Name: loan_amnt, dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['loan_amnt'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic plot for app experiment\n",
    "# two variables (both numbers)\n",
    "# 1 int_rate max3.099000e+01 min5.310000e+00\n",
    "# 2 loan_amt max4.000000e+04 min5.000000e+02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "import plotly.express as px\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train[['int_rate', 'loan_amnt']]\n",
    "y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    ce.OneHotEncoder(use_cat_names=True), \n",
    "    LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('onehotencoder',\n",
       "                 OneHotEncoder(cols=[], drop_invariant=False,\n",
       "                               handle_missing='value', handle_unknown='value',\n",
       "                               return_df=True, use_cat_names=True, verbose=0)),\n",
       "                ('linearregression',\n",
       "                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "                                  normalize=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pipeline.joblib']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(pipeline, 'pipeline.joblib', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joblib==0.14.0\n",
      "scikit-learn==0.21.3\n",
      "category_encoders==2.1.0\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import sklearn\n",
    "import category_encoders as ce\n",
    "print(f'joblib=={joblib.__version__}')\n",
    "print(f'scikit-learn=={sklearn.__version__}')\n",
    "print(f'category_encoders=={ce.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/lineality/dash-template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use these exact versions in the \n",
    "#joblib==0.14.0\n",
    "#scikit-learn==0.21.3\n",
    "#category_encoders==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install\n",
    "# pipenv install joblib==0.14.0\n",
    "# pipenv install scikit-learn==0.21.3\n",
    "# pipenv install category_encoders==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.714656\tvalidation_1-auc:0.640288\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-auc:0.722411\tvalidation_1-auc:0.635976\n",
      "[2]\tvalidation_0-auc:0.723778\tvalidation_1-auc:0.645463\n",
      "[3]\tvalidation_0-auc:0.727593\tvalidation_1-auc:0.63831\n",
      "[4]\tvalidation_0-auc:0.729922\tvalidation_1-auc:0.642938\n",
      "[5]\tvalidation_0-auc:0.729169\tvalidation_1-auc:0.647532\n",
      "[6]\tvalidation_0-auc:0.730365\tvalidation_1-auc:0.638445\n",
      "[7]\tvalidation_0-auc:0.730692\tvalidation_1-auc:0.642786\n",
      "[8]\tvalidation_0-auc:0.730653\tvalidation_1-auc:0.636204\n",
      "[9]\tvalidation_0-auc:0.73069\tvalidation_1-auc:0.638751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=10, n_jobs=-1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "processor = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='median')\n",
    ")\n",
    "\n",
    "X_train_processed = processor.fit_transform(X_train)\n",
    "X_val_processed = processor.transform(X_val)\n",
    "\n",
    "eval_set = [(X_train_processed, y_train), \n",
    "            (X_val_processed, y_val)]\n",
    "\n",
    "#model = XGBClassifier(n_estimators=1000, n_jobs=-1)\n",
    "model = XGBClassifier(n_estimators=10, n_jobs=-1)\n",
    "model.fit(X_train_processed, y_train, eval_set=eval_set, eval_metric='auc', \n",
    "          early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC for class 1:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unknown format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-bad404bbc4fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_processed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Test ROC AUC for class {class_index}:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_proba\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\unit2\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    353\u001b[0m     return _average_binary_score(\n\u001b[0;32m    354\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\unit2\\lib\\site-packages\\sklearn\\metrics\\base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: unknown format is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "X_test_processed = processor.transform(X_test)\n",
    "class_index = 1\n",
    "y_pred_proba = model.predict_proba(X_test_processed)[:, class_index]\n",
    "print(f'Test ROC AUC for class {class_index}:')\n",
    "print(roc_auc_score(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-b40cac6bfded>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m y_pred_proba = cross_val_predict(pipe, X_train, y_train, cv=5, n_jobs=-1, \n\u001b[0m\u001b[0;32m      2\u001b[0m                                  method='predict_proba')[:, 1]\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_proba\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred_proba = cross_val_predict(pipe, X_train, y_train, cv=5, n_jobs=-1, \n",
    "                                 method='predict_proba')[:, 1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_train, y_pred_proba)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "print('Area under the Receiver Operating Characteristic curve:', \n",
    "      roc_auc_score(y_train, y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'XGBClassifier' object has no attribute 'evals_result_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-12a90674c2b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validation_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'auc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mval_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validation_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'auc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unit2/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mevals_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    874\u001b[0m             'validation_1': {'logloss': ['0.41965', '0.17686']}}\n\u001b[1;32m    875\u001b[0m         \"\"\"\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevals_result_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m             \u001b[0mevals_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevals_result_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'XGBClassifier' object has no attribute 'evals_result_'"
     ]
    }
   ],
   "source": [
    "results = model.evals_result()\n",
    "train_error = results['validation_0']['auc']\n",
    "val_error = results['validation_1']['auc']\n",
    "epoch = range(1, len(train_error)+1)\n",
    "plt.plot(epoch, train_error, label='Train')\n",
    "plt.plot(epoch, val_error, label='Validation')\n",
    "plt.ylabel('Classification Error')\n",
    "plt.xlabel('Model Complexity (n_estimators)')\n",
    "plt.ylim((0.18, 0.22)) # Zoom in\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-in-python\n",
    "# How to print an AUC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eli5 permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "                       oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='median')\n",
    ")\n",
    "\n",
    "X_train_transformed = transformers.fit_transform(X_train)\n",
    "X_val_transformed = transformers.transform(X_val)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=10, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PermutationImportance(cv='prefit',\n",
       "                      estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                       class_weight=None,\n",
       "                                                       criterion='gini',\n",
       "                                                       max_depth=None,\n",
       "                                                       max_features='auto',\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=1,\n",
       "                                                       min_samples_split=2,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       n_estimators=10,\n",
       "                                                       n_jobs=-1,\n",
       "                                                       oob_score=False,\n",
       "                                                       random_state=42,\n",
       "                                                       verbose=0,\n",
       "                                                       warm_start=False),\n",
       "                      n_iter=5, random_state=42, refit=True,\n",
       "                      scoring='accuracy')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permuter = PermutationImportance(\n",
    "    model, \n",
    "    scoring='accuracy', \n",
    "    n_iter=5, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "permuter.fit(X_val_transformed, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "debt_settlement_flag    0.033508\n",
       "installment             0.027423\n",
       "loan_amnt               0.022437\n",
       "funded_amnt             0.022211\n",
       "revol_bal               0.008651\n",
       "annual_inc              0.004377\n",
       "open_acc                0.004196\n",
       "total_acc               0.003976\n",
       "term                    0.003810\n",
       "int_rate                0.003765\n",
       "home_ownership          0.002733\n",
       "sub_grade               0.001586\n",
       "purpose                 0.000963\n",
       "grade                   0.000801\n",
       "earliest_cr_line        0.000599\n",
       "pub_rec                 0.000432\n",
       "addr_state              0.000124\n",
       "hardship_flag           0.000000\n",
       "policy_code             0.000000\n",
       "day                     0.000000\n",
       "year                    0.000000\n",
       "application_type       -0.000006\n",
       "disbursement_method    -0.000014\n",
       "month                  -0.000117\n",
       "verification_status    -0.000390\n",
       "dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = X_val.columns.tolist()\n",
    "pd.Series(permuter.feature_importances_, feature_names).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0335\n",
       "                \n",
       "                    &plusmn; 0.0003\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                debt_settlement_flag\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 82.62%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0274\n",
       "                \n",
       "                    &plusmn; 0.0004\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                installment\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.90%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0224\n",
       "                \n",
       "                    &plusmn; 0.0003\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                loan_amnt\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0222\n",
       "                \n",
       "                    &plusmn; 0.0002\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                funded_amnt\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.25%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0087\n",
       "                \n",
       "                    &plusmn; 0.0004\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                revol_bal\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0044\n",
       "                \n",
       "                    &plusmn; 0.0002\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                annual_inc\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.33%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0042\n",
       "                \n",
       "                    &plusmn; 0.0005\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                open_acc\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.50%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0040\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                total_acc\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.63%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0038\n",
       "                \n",
       "                    &plusmn; 0.0003\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                term\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.67%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0038\n",
       "                \n",
       "                    &plusmn; 0.0003\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                int_rate\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.54%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0027\n",
       "                \n",
       "                    &plusmn; 0.0002\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                home_ownership\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.64%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0016\n",
       "                \n",
       "                    &plusmn; 0.0004\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                sub_grade\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.33%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0010\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                purpose\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.53%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0008\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                grade\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.80%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0006\n",
       "                \n",
       "                    &plusmn; 0.0004\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                earliest_cr_line\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.05%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0004\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                pub_rec\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.60%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0001\n",
       "                \n",
       "                    &plusmn; 0.0003\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                addr_state\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                hardship_flag\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                policy_code\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                day\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                year\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 99.95%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0000\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                application_type\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 99.91%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0000\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                disbursement_method\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 99.62%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0001\n",
       "                \n",
       "                    &plusmn; 0.0004\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                month\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 99.11%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0004\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                verification_status\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_weights(\n",
    "    permuter, \n",
    "    top=None, # show permutation importances for all features\n",
    "    feature_names=feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiments after here do not run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((308125, 25), (983948, 25), (308125, 25), (983948, 25))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = ce.OrdinalEncoder()\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "X_val_encoded = encoder.transform(X_val)\n",
    "\n",
    "X_train.shape, X_val.shape, X_train_encoded.shape, X_val_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = [(X_train_encoded, y_train), \n",
    "            (X_val_encoded, y_val)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "    n_estimators=10, # <= 1000 trees, depends on early stopping\n",
    "    max_depth=7,       # try deeper trees because of high cardinality categoricals\n",
    "    learning_rate=0.1, # try higher learning rate\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[13:52:55] /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/metric/multiclass_metric.cu:32: Check failed: label_error >= 0 && label_error < static_cast<int32_t>(n_class): MultiClassEvaluation: label must be in [0, num_class), num_class=1 but found 1 in label\nStack trace:\n  [bt] (0) /home/adumbrate/anaconda3/envs/unit2/lib/libxgboost.so(+0x1439af) [0x7f92c2cdc9af]\n  [bt] (1) /home/adumbrate/anaconda3/envs/unit2/lib/libxgboost.so(+0x11430b) [0x7f92c2cad30b]\n  [bt] (2) /home/adumbrate/anaconda3/envs/unit2/lib/libxgboost.so(XGBoosterEvalOneIter+0x31a) [0x7f92c2c15c4a]\n  [bt] (3) /home/adumbrate/anaconda3/envs/unit2/lib/python3.7/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f9400425ec0]\n  [bt] (4) /home/adumbrate/anaconda3/envs/unit2/lib/python3.7/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f940042587d]\n  [bt] (5) /home/adumbrate/anaconda3/envs/unit2/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f940063cede]\n  [bt] (6) /home/adumbrate/anaconda3/envs/unit2/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12914) [0x7f940063d914]\n  [bt] (7) /home/adumbrate/anaconda3/envs/unit2/bin/python(_PyObject_FastCallKeywords+0x49b) [0x7f94039348fb]\n  [bt] (8) /home/adumbrate/anaconda3/envs/unit2/bin/python(_PyEval_EvalFrameDefault+0x52f8) [0x7f94039986e8]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-cdd1db2ca24f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(X_train_encoded, y_train, eval_set=eval_set, \n\u001b[0;32m----> 2\u001b[0;31m           eval_metric='merror', early_stopping_rounds=10)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/unit2/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unit2/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unit2/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# check evaluation result.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mbst_eval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst_eval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTRING_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst_eval_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unit2/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36meval_set\u001b[0;34m(self, evals, iteration, feval)\u001b[0m\n\u001b[1;32m   1170\u001b[0m                                               \u001b[0mdmats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m                                               \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m                                               ctypes.byref(msg)))\n\u001b[0m\u001b[1;32m   1173\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unit2/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \"\"\"\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [13:52:55] /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/metric/multiclass_metric.cu:32: Check failed: label_error >= 0 && label_error < static_cast<int32_t>(n_class): MultiClassEvaluation: label must be in [0, num_class), num_class=1 but found 1 in label\nStack trace:\n  [bt] (0) /home/adumbrate/anaconda3/envs/unit2/lib/libxgboost.so(+0x1439af) [0x7f92c2cdc9af]\n  [bt] (1) /home/adumbrate/anaconda3/envs/unit2/lib/libxgboost.so(+0x11430b) [0x7f92c2cad30b]\n  [bt] (2) /home/adumbrate/anaconda3/envs/unit2/lib/libxgboost.so(XGBoosterEvalOneIter+0x31a) [0x7f92c2c15c4a]\n  [bt] (3) /home/adumbrate/anaconda3/envs/unit2/lib/python3.7/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f9400425ec0]\n  [bt] (4) /home/adumbrate/anaconda3/envs/unit2/lib/python3.7/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f940042587d]\n  [bt] (5) /home/adumbrate/anaconda3/envs/unit2/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f940063cede]\n  [bt] (6) /home/adumbrate/anaconda3/envs/unit2/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12914) [0x7f940063d914]\n  [bt] (7) /home/adumbrate/anaconda3/envs/unit2/bin/python(_PyObject_FastCallKeywords+0x49b) [0x7f94039348fb]\n  [bt] (8) /home/adumbrate/anaconda3/envs/unit2/bin/python(_PyEval_EvalFrameDefault+0x52f8) [0x7f94039986e8]\n\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_encoded, y_train, eval_set=eval_set, \n",
    "          eval_metric='merror', early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying Random Forest Feature Importance (note: there are no categoricals...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scikit-learn Random Forest feature importance ... tends to inflate the importance of continuous or high-cardinality categorical variables. ... Breiman and Cutler, the inventors of Random Forests, indicate that this method of “adding up the gini decreases for each individual variable over all trees in the forest gives a fast variable importance that is often very consistent with the permutation importance measure.” — Beware Default Random Forest Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make pipeline\n",
    "pipeline = make_pipeline(\n",
    "    #encode varibles\n",
    "    ce.OrdinalEncoder(),\n",
    "    #here there are few/no NaN values (in first sweep)\n",
    "    SimpleImputer(strategy='median'), \n",
    "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.8281108351254335\n"
     ]
    }
   ],
   "source": [
    "# Fitting on train, scoring on val\n",
    "pipeline.fit(X_train, y_train)\n",
    "print('Validation Accuracy', pipeline.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on train, score on val\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_val)\n",
    "#print('Validation Accuracy', accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 34779, 154988],\n",
       "       [ 14142, 780039]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Charged Off', 'Fully Paid'], dtype='<U11')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to get labels\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "unique_labels(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Predicted Charged Off', 'Predicted Fully Paid'],\n",
       " ['Actual Charged Off', 'Actual Fully Paid'])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Check that our labels are correct\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    labels = unique_labels(y_true)\n",
    "    columns = [f'Predicted {label}' for label in labels]\n",
    "    index = [f'Actual {label}' for label in labels]\n",
    "    return columns, index\n",
    "\n",
    "plot_confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Charged Off</th>\n",
       "      <th>Predicted Fully Paid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Charged Off</th>\n",
       "      <td>34779</td>\n",
       "      <td>154988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Fully Paid</th>\n",
       "      <td>14142</td>\n",
       "      <td>780039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Predicted Charged Off  Predicted Fully Paid\n",
       "Actual Charged Off                  34779                154988\n",
       "Actual Fully Paid                   14142                780039"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Make it a pandas dataframe\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    labels = unique_labels(y_true)\n",
    "    columns = [f'Predicted {label}' for label in labels]\n",
    "    index = [f'Actual {label}' for label in labels]\n",
    "    table = pd.DataFrame(confusion_matrix(y_true, y_pred), \n",
    "                         columns=columns, index=index)\n",
    "    return table\n",
    "\n",
    "plot_confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Plot a heatmap\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    labels = unique_labels(y_true)\n",
    "    columns = [f'Predicted {label}' for label in labels]\n",
    "    index = [f'Actual {label}' for label in labels]\n",
    "    table = pd.DataFrame(confusion_matrix(y_true, y_pred), \n",
    "                         columns=columns, index=index)\n",
    "    #return sns.heatmap(table, annot=True, fmt='d', cmap='viridis')\n",
    "    return sns.heatmap(table)\n",
    "\n",
    "plot_confusion_matrix(y_val, y_pred);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "#%matplotlib nbagg\n",
    "#%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "rf = pipeline.named_steps['randomforestclassifier']\n",
    "importances = pd.Series(rf.feature_importances_, X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "# Plot feature importances\n",
    "#colab\n",
    "#%matplotlib inline \n",
    "#jupyter notebooks\n",
    "%matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "plt.figure(figsize=(10,n/2))\n",
    "plt.title(f'Top {n} features')\n",
    "importances.sort_values()[-n:].plot.barh(color='green');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport category_encoders as ce\\nfrom sklearn.impute import SimpleImputer\\nfrom sklearn.pipeline import make_pipeline\\nfrom xgboost import XGBClassifier\\n\\nprocessor = make_pipeline(\\n    ce.OrdinalEncoder(), \\n    SimpleImputer(strategy=\\'median\\')\\n)\\n\\nX_train_processed = processor.fit_transform(X_train)\\nX_val_processed = processor.transform(X_val)\\n\\neval_set = [(X_train_processed, y_train), \\n            (X_val_processed, y_val)]\\n\\nmodel = XGBClassifier(n_estimators=1000, n_jobs=-1)\\nmodel.fit(X_train_processed, y_train, eval_set=eval_set, eval_metric=\\'auc\\', \\n          early_stopping_rounds=10)\\n\\n# THIS CELL ISN\\'T ABOUT THE NEW OBJECTIVES FOR TODAY\\n# BUT IT IS IMPORTANT FOR YOUR SPRINT CHALLENGE\\n\\nfrom sklearn.metrics import roc_auc_score\\nX_test_processed = processor.transform(X_test)\\nclass_index = 1\\ny_pred_proba = model.predict_proba(X_test_processed)[:, class_index]\\nprint(f\\'Test ROC AUC for class {class_index}:\\')\\nprint(roc_auc_score(y_test, y_pred_proba)) # Ranges from 0-1, higher is better\\n\\ndf = pd.DataFrame({\\n    \\'id\\': test_id, \\n    \\'pred_proba\\': y_pred_proba, \\n    \\'status_group\\': y_test\\n})\\n\\ndf = df.merge(\\n     history[[\\'id\\', \\'issue_d\\', \\'sub_grade\\', \\'percent_paid\\', \\'term\\', \\'int_rate\\']], \\n     how=\\'left\\'\\n)\\n\\ndf.head()\\n\\nfully_paid = df[\\'status_group\\'] == \\'Fully Paid\\'\\ncharged_off = ~fully_paid\\nright = (fully_paid) == (df[\\'pred_proba\\'] > 0.50)\\nwrong = ~right\\n\\ndf[fully_paid & right].sample(n=10, random_state=1).sort_values(by=\\'pred_proba\\')\\n\\n# To explain the prediction for test observaition with index #3094,\\n# first, get all of the features for that observation\\nrow = X_test.iloc[[3094]]\\n\\n# STUDY/PRACTICE THIS CELL FOR THE SPRINT CHALLENGE\\nimport shap\\n\\nexplainer = shap.TreeExplainer(model)\\nrow_processed = processor.transform(row)\\nshap_values = explainer.shap_values(row_processed)\\n\\nshap.initjs()\\nshap.force_plot(\\n    base_value=explainer.expected_value, \\n    shap_values=shap_values, \\n    features=row\\n)\\n\\nfeature_names = row.columns\\nfeature_values = row.values[0]\\nshaps = pd.Series(shap_values[0], zip(feature_names, feature_values))\\nshaps.sort_values().plot.barh(color=\\'grey\\', figsize=(15,20));\\n\\npros = shaps.sort_values(ascending=False)[:3].index\\ncons = shaps.sort_values(ascending=True)[:3].index\\n\\nprint(\\'Top 3 reasons for prediction:\\')\\nfor i, pro in enumerate(pros, start=1):\\n    feature_name, feature_value = pro\\n    print(f\\'{i}. {feature_name} is {feature_value}.\\')\\n\\nprint(\\'\\n\\')\\nprint(\\'Cons:\\')\\nfor i, con in enumerate(cons, start=1):\\n    feature_name, feature_value = con\\n    print(f\\'{i}. {feature_name} is {feature_value}.\\')\\n\\ndef explain(row_number):\\n    positive_class = \\'Fully Paid\\'\\n    positive_class_index = 1\\n    \\n    \\n    # Get & process the data for the row\\n    row = X_test.iloc[[row_number]]\\n    row_processed = processor.transform(row)\\n    \\n    # Make predictions (includes predicted probability)\\n    pred = model.predict(row_processed)[0]\\n    pred_proba = model.predict_proba(row_processed)[0, positive_class_index]\\n    pred_proba *= 100\\n    if pred != positive_class:\\n        pred_proba = 100 - pred_proba\\n    \\n    # Show predictiion & probability\\n    print(f\\'The model predicts this loan is {pred}, with {pred_proba:.0f}% probability.\\')\\n    \\n    # Get shapley additive explanations\\n    shap_values = explainer.shap_values(row_processed)\\n    \\n    # Get top 3 \"pros & cons\"\\n    feature_names = row.columns\\n    feature_values = row.values[0]\\n    shaps = pd.Series(shap_values[0], zip(feature_names, feature_values))\\n    pros = shaps.sort_values(ascending=False)[:3].index\\n    cons = shaps.sort_values(ascending=True)[:3].index\\n    \\n    # Show top 3 reasons for prediction\\n    print(\\'\\n\\')\\n    print(\\'Top 3 reasons for prediction:\\')\\n    evidence = pros if pred == positive_class else cons\\n    for i, info in enumerate(evidence, start=1):\\n        feature_name, feature_value = info\\n        print(f\\'{i}. {feature_name} is {feature_value}.\\')\\n    \\n    # Show top 1 counter-argument against prediction\\n    print(\\'\\n\\')\\n    print(\\'Top counter-argument against prediction:\\')\\n    evidence = cons if pred == positive_class else pros\\n    feature_name, feature_value = evidence[0]\\n    print(f\\'- {feature_name} is {feature_value}.\\')\\n    \\n    # Show Shapley Values Force Plot\\n    shap.initjs()\\n    return shap.force_plot(\\n        base_value=explainer.expected_value, \\n        shap_values=shap_values, \\n        features=row\\n    )\\n\\n    \\nexplain(3094)\\n\\ndf[charged_off & right].sample(n=10, random_state=1).sort_values(by=\\'pred_proba\\')\\n\\nexplain(8383)\\n\\ndf[fully_paid & wrong].sample(n=10, random_state=1).sort_values(by=\\'pred_proba\\')\\n\\nexplain(18061)\\n\\nexplain(6763)\\n\\ndf[charged_off & wrong].sample(n=10, random_state=1).sort_values(by=\\'pred_proba\\')\\n\\nexplain(19883)\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "processor = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='median')\n",
    ")\n",
    "\n",
    "X_train_processed = processor.fit_transform(X_train)\n",
    "X_val_processed = processor.transform(X_val)\n",
    "\n",
    "eval_set = [(X_train_processed, y_train), \n",
    "            (X_val_processed, y_val)]\n",
    "\n",
    "model = XGBClassifier(n_estimators=1000, n_jobs=-1)\n",
    "model.fit(X_train_processed, y_train, eval_set=eval_set, eval_metric='auc', \n",
    "          early_stopping_rounds=10)\n",
    "\n",
    "# THIS CELL ISN'T ABOUT THE NEW OBJECTIVES FOR TODAY\n",
    "# BUT IT IS IMPORTANT FOR YOUR SPRINT CHALLENGE\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "X_test_processed = processor.transform(X_test)\n",
    "class_index = 1\n",
    "y_pred_proba = model.predict_proba(X_test_processed)[:, class_index]\n",
    "print(f'Test ROC AUC for class {class_index}:')\n",
    "print(roc_auc_score(y_test, y_pred_proba)) # Ranges from 0-1, higher is better\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'id': test_id, \n",
    "    'pred_proba': y_pred_proba, \n",
    "    'status_group': y_test\n",
    "})\n",
    "\n",
    "df = df.merge(\n",
    "     history[['id', 'issue_d', 'sub_grade', 'percent_paid', 'term', 'int_rate']], \n",
    "     how='left'\n",
    ")\n",
    "\n",
    "df.head()\n",
    "\n",
    "fully_paid = df['status_group'] == 'Fully Paid'\n",
    "charged_off = ~fully_paid\n",
    "right = (fully_paid) == (df['pred_proba'] > 0.50)\n",
    "wrong = ~right\n",
    "\n",
    "df[fully_paid & right].sample(n=10, random_state=1).sort_values(by='pred_proba')\n",
    "\n",
    "# To explain the prediction for test observaition with index #3094,\n",
    "# first, get all of the features for that observation\n",
    "row = X_test.iloc[[3094]]\n",
    "\n",
    "# STUDY/PRACTICE THIS CELL FOR THE SPRINT CHALLENGE\n",
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "row_processed = processor.transform(row)\n",
    "shap_values = explainer.shap_values(row_processed)\n",
    "\n",
    "shap.initjs()\n",
    "shap.force_plot(\n",
    "    base_value=explainer.expected_value, \n",
    "    shap_values=shap_values, \n",
    "    features=row\n",
    ")\n",
    "\n",
    "feature_names = row.columns\n",
    "feature_values = row.values[0]\n",
    "shaps = pd.Series(shap_values[0], zip(feature_names, feature_values))\n",
    "shaps.sort_values().plot.barh(color='grey', figsize=(15,20));\n",
    "\n",
    "pros = shaps.sort_values(ascending=False)[:3].index\n",
    "cons = shaps.sort_values(ascending=True)[:3].index\n",
    "\n",
    "print('Top 3 reasons for prediction:')\n",
    "for i, pro in enumerate(pros, start=1):\n",
    "    feature_name, feature_value = pro\n",
    "    print(f'{i}. {feature_name} is {feature_value}.')\n",
    "\n",
    "print('\\n')\n",
    "print('Cons:')\n",
    "for i, con in enumerate(cons, start=1):\n",
    "    feature_name, feature_value = con\n",
    "    print(f'{i}. {feature_name} is {feature_value}.')\n",
    "\n",
    "def explain(row_number):\n",
    "    positive_class = 'Fully Paid'\n",
    "    positive_class_index = 1\n",
    "    \n",
    "    \n",
    "    # Get & process the data for the row\n",
    "    row = X_test.iloc[[row_number]]\n",
    "    row_processed = processor.transform(row)\n",
    "    \n",
    "    # Make predictions (includes predicted probability)\n",
    "    pred = model.predict(row_processed)[0]\n",
    "    pred_proba = model.predict_proba(row_processed)[0, positive_class_index]\n",
    "    pred_proba *= 100\n",
    "    if pred != positive_class:\n",
    "        pred_proba = 100 - pred_proba\n",
    "    \n",
    "    # Show predictiion & probability\n",
    "    print(f'The model predicts this loan is {pred}, with {pred_proba:.0f}% probability.')\n",
    "    \n",
    "    # Get shapley additive explanations\n",
    "    shap_values = explainer.shap_values(row_processed)\n",
    "    \n",
    "    # Get top 3 \"pros & cons\"\n",
    "    feature_names = row.columns\n",
    "    feature_values = row.values[0]\n",
    "    shaps = pd.Series(shap_values[0], zip(feature_names, feature_values))\n",
    "    pros = shaps.sort_values(ascending=False)[:3].index\n",
    "    cons = shaps.sort_values(ascending=True)[:3].index\n",
    "    \n",
    "    # Show top 3 reasons for prediction\n",
    "    print('\\n')\n",
    "    print('Top 3 reasons for prediction:')\n",
    "    evidence = pros if pred == positive_class else cons\n",
    "    for i, info in enumerate(evidence, start=1):\n",
    "        feature_name, feature_value = info\n",
    "        print(f'{i}. {feature_name} is {feature_value}.')\n",
    "    \n",
    "    # Show top 1 counter-argument against prediction\n",
    "    print('\\n')\n",
    "    print('Top counter-argument against prediction:')\n",
    "    evidence = cons if pred == positive_class else pros\n",
    "    feature_name, feature_value = evidence[0]\n",
    "    print(f'- {feature_name} is {feature_value}.')\n",
    "    \n",
    "    # Show Shapley Values Force Plot\n",
    "    shap.initjs()\n",
    "    return shap.force_plot(\n",
    "        base_value=explainer.expected_value, \n",
    "        shap_values=shap_values, \n",
    "        features=row\n",
    "    )\n",
    "\n",
    "    \n",
    "explain(3094)\n",
    "\n",
    "df[charged_off & right].sample(n=10, random_state=1).sort_values(by='pred_proba')\n",
    "\n",
    "explain(8383)\n",
    "\n",
    "df[fully_paid & wrong].sample(n=10, random_state=1).sort_values(by='pred_proba')\n",
    "\n",
    "explain(18061)\n",
    "\n",
    "explain(6763)\n",
    "\n",
    "df[charged_off & wrong].sample(n=10, random_state=1).sort_values(by='pred_proba')\n",
    "\n",
    "explain(19883)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('ordinalencoder',\n",
       "                 OrdinalEncoder(cols=['disbursement_method',\n",
       "                                      'debt_settlement_flag', 'hardship_flag',\n",
       "                                      'application_type', 'addr_state',\n",
       "                                      'purpose', 'earliest_cr_line',\n",
       "                                      'home_ownership', 'verification_status',\n",
       "                                      'term', 'grade', 'sub_grade'],\n",
       "                                drop_invariant=False, handle_missing='value',\n",
       "                                handle_unknown='value',\n",
       "                                mapping=[{'col': 'disburseme...\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "                               max_delta_step=0, max_depth=3,\n",
       "                               min_child_weight=1, missing=None,\n",
       "                               n_estimators=100, n_jobs=-1, nthread=None,\n",
       "                               objective='binary:logistic', random_state=42,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               seed=None, silent=None, subsample=1,\n",
       "                               verbosity=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.8314677198388533\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = pipeline.predict(X_val)\n",
    "print('Validation Accuracy', accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_encoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-ec603e4bd57f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpdpbox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpdp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sex'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpdp_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdp_isolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mpdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdp_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdp_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_encoded' is not defined"
     ]
    }
   ],
   "source": [
    "# Use Pdpbox\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pdpbox import pdp\n",
    "feature = 'sex'\n",
    "pdp_dist = pdp.pdp_isolate(model=model, dataset=X_encoded, model_features=features, feature=feature)\n",
    "pdp.pdp_plot(pdp_dist, feature);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
